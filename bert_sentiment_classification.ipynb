{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import transformers as ppb\n",
    "\n",
    "import warnings\n",
    "import os.path as path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device type: cuda\n"
     ]
    }
   ],
   "source": [
    "# print messages\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# device for training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device type: {device.type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we will use in this example is [SST2](https://nlp.stanford.edu/sentiment/index.html), which contains sentences from movie reviews, each labeled as either positive (has the value 1) or negative (has the value 0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = \"./data/sst2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3610\n",
       "0    3310\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(f\"{DATASET_DIR}/train.tsv\", delimiter = '\\t', header = None)\n",
    "\n",
    "train_df[1].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Pre-trained DistilBERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained model/tokenizer\n",
    "\n",
    "# For DistilBERT:\n",
    "tokenizer = ppb.DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = ppb.DistilBertModel.from_pretrained('distilbert-base-uncased').to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first step is to tokenize the sentences -- break them up into word and subwords in the format BERT is comfortable with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = train_df[0].apply(lambda x: tokenizer.encode(x, add_special_tokens = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [101, 1037, 18385, 1010, 6057, 1998, 2633, 182...\n",
       "1       [101, 4593, 2128, 27241, 23931, 2013, 1996, 62...\n",
       "2       [101, 2027, 3653, 23545, 2037, 4378, 24185, 10...\n",
       "3       [101, 2023, 2003, 1037, 17453, 14726, 19379, 1...\n",
       "4       [101, 5655, 6262, 1005, 1055, 12075, 2571, 376...\n",
       "                              ...                        \n",
       "6915    [101, 9145, 1010, 7570, 18752, 14116, 1998, 28...\n",
       "6916    [101, 2202, 2729, 2003, 19957, 2864, 2011, 103...\n",
       "6917    [101, 1996, 5896, 4472, 4121, 1010, 3082, 7832...\n",
       "6918    [101, 1037, 5667, 2919, 2143, 2007, 5667, 2561...\n",
       "6919    [101, 1037, 12090, 2135, 2512, 5054, 19570, 23...\n",
       "Name: 0, Length: 6920, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length: 67\n"
     ]
    }
   ],
   "source": [
    "# find max length among all sentences\n",
    "\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "        \n",
    "print(f\"Max sentence length: {max_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  101,  1037, 18385, ...,     0,     0,     0],\n",
       "       [  101,  4593,  2128, ...,     0,     0,     0],\n",
       "       [  101,  2027,  3653, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  101,  1996,  5896, ...,     0,     0,     0],\n",
       "       [  101,  1037,  5667, ...,     0,     0,     0],\n",
       "       [  101,  1037, 12090, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded = np.array([i + [0] * (max_len - len(i)) for i in tokenized.values])\n",
    "padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6920, 67)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we directly send padded to BERT, that would slightly confuse it. We need to create another variable to tell it to ignore (mask) the padding we've added when it's processing its input.  \n",
    "That's what *attention_mask* is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6920, 67)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling: Using BERT to Embed All Input Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensors = torch.tensor(padded).to(device)\n",
    "attention_mask = torch.tensor(attention_mask).to(device)\n",
    "\n",
    "example_n = input_tensors.shape[0]\n",
    "features = torch.zeros((example_n, 768)).to(device)\n",
    "\n",
    "# using pretrained model for embedding, it's not a part of training. so turn the auto rad off\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for i in range(0, example_n, BATCH_SIZE):\n",
    "        \n",
    "        END = (i + BATCH_SIZE) if (i + BATCH_SIZE < example_n) else (example_n)\n",
    "        \n",
    "        last_hidden_states = model(input_tensors[i:END], attention_mask = attention_mask[i:END] )\n",
    "        \n",
    "        # The embedded CLS token can be thought of as an embedding for the entire sentence!!\n",
    "        features[i:END] = last_hidden_states[0][:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6920, 768])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6920])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.tensor(train_df[1].values, dtype=torch.float).to(device)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_TEST_RATIO = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_features.shape: torch.Size([5190, 768])\n",
      "train_labels.shape: torch.Size([5190])\n",
      "test_features.shape: torch.Size([1730, 768])\n",
      "test_labels.shape: torch.Size([1730])\n"
     ]
    }
   ],
   "source": [
    "# create shuffled indexs\n",
    "perm = torch.randperm(example_n)\n",
    "\n",
    "# indexs for training set\n",
    "indexs = perm[ : int(example_n * TRAIN_TEST_RATIO)]\n",
    "\n",
    "# indexs for test set\n",
    "mask = torch.ones((example_n,), dtype=torch.bool)\n",
    "mask[indexs] = 0\n",
    "\n",
    "# training set\n",
    "train_features = features[indexs]\n",
    "train_labels = labels[indexs]\n",
    "\n",
    "# test set\n",
    "test_features = features[mask]\n",
    "test_labels = labels[mask]\n",
    "\n",
    "print(f\"train_features.shape: {train_features.shape}\")\n",
    "print(f\"train_labels.shape: {train_labels.shape}\")\n",
    "\n",
    "print(f\"test_features.shape: {test_features.shape}\")\n",
    "print(f\"test_labels.shape: {test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downstream Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.001 # learning rate\n",
    "EPOCH = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dimension = 768):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        self.linear = nn.Linear(input_dimension, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        prediction = F.sigmoid(self.linear(x))\n",
    "        \n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model instance\n",
    "\n",
    "sentiment_classifier = SentimentClassifier(768).to(device)\n",
    "\n",
    "# loss function: binary cross-entropy\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "# create optimizer instance\n",
    "\n",
    "optimizer = torch.optim.Adam(sentiment_classifier.parameters(), lr = LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_losses = []\n",
    "for epoch in range(EPOCH):\n",
    "    \n",
    "    batch_losses = []\n",
    "    \n",
    "    for i in range(0, train_features.size(0), BATCH_SIZE):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        END = (i + BATCH_SIZE) if (i + BATCH_SIZE) < train_features.size(0) else train_features.size(0)\n",
    "        \n",
    "        batch = train_features[i:END]\n",
    "    \n",
    "        # forward\n",
    "        predicted = sentiment_classifier(batch)\n",
    "        \n",
    "        # compute loss\n",
    "        loss = criterion(predicted, train_labels[i:END].unsqueeze(1))\n",
    "        \n",
    "        # backward propagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_losses.append(loss)\n",
    "        \n",
    "    epoch_losses.append(torch.tensor(batch_losses).mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(epoch_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score on test set: 0.9124356825969728\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    test_predicted = sentiment_classifier(test_features).squeeze(1)\n",
    "    \n",
    "    roc_scores = roc_auc_score(test_labels.cpu(), test_predicted.cpu())\n",
    "    \n",
    "    print(f\"ROC AUC score on test set: {roc_scores}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
